{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWEB SCRAPPING\\n\\nTo install requests-html and jupyter in virtualenv\\n\\n# pipenv install requests -html \\n\\nTo start jupyter notebook from virtualenv\\n\\n# pipenv run jupyter notebook\\n\\n# http://python-requests.org/\\n\\n#print(response.content) - will get you the content of the website\\n\\n#alway add \".\" before the class for e.g. \".subtext\"\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "WEB SCRAPPING\n",
    "\n",
    "To install requests-html and jupyter in virtualenv\n",
    "\n",
    "# pipenv install requests -html \n",
    "\n",
    "To start jupyter notebook from virtualenv\n",
    "\n",
    "# pipenv run jupyter notebook\n",
    "\n",
    "# http://python-requests.org/\n",
    "\n",
    "#print(response.content) - will get you the content of the website\n",
    "\n",
    "#alway add \".\" before the class for e.g. \".subtext\"\n",
    "\n",
    "#Reference: https://github.com/pycampers/foundation_bootcamp/blob/master/6th_sept_web_scraping.ipynb\n",
    "\n",
    "#first = True - means just give the frist value not the list\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "\n",
    "website_url = \"https://news.ycombinator.com/\"\n",
    "\n",
    "response = session.get(website_url)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(response.content)\n",
    "#print(response.html.links)\n",
    "#print(response.html.find(\"a\")) - \"a\" will find an anchor tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9th Circuit holds that scraping a public website does not violate the CFAA [pdf] (uscourts.gov)', '94k Bitcoin (1B USD) transferred from unknown wallet to unknown wallet (twitter.com)', 'Daytripper (github.com)', 'Running GitHub on Rails 6.0 (github.blog)', '‘We May Have to Shoot Down This Aircraft’ (politico.com)', 'Unencrypted patient medical information is being broadcast across Vancouver (openprivacy.ca)', \"Menstruation Apps Are Sharing Users' Data (privacyinternational.org)\", 'New games for the Atari Lynx (atarigamer.com)', 'The Buffalo Public Library in 1983 (1883) (wikisource.org)', 'Maturity (gitlab.com)', 'Why Positive Cashflow Matters (avc.com)', 'Project Naptha: Make Text in Browser Images Selectable (projectnaptha.com)', 'Ribbon (YC S17) is hiring data engineers. Help us simplify healthcare (ribbonhealth.com)', 'Waltz: A Distributed Write-Ahead Log (wepay.com)', 'Hong Kong Protests: The most striking illustrations from the movement so far (digitalartsonline.co.uk)', 'GPT-2 is not as dangerous as OpenAI thought it might be (nostalgebraist.tumblr.com)', 'Announcing Ballerina 1.0 a langauge with structural type system (ballerina.io)', 'Show HN: Enter your URL and view CVEs affecting your stack over last 6 months (secalerts.co)', 'High doses of vitamin D do not strengthen bone (jamanetwork.com)', 'Scientists Discover New Evidence of the Asteroid That Killed Off the Dinosaurs (wsj.com)', 'Sunsetting Python 2 (python.org)', 'The Book Disease: On Bibliomania (laphamsquarterly.org)', 'Questions to ask a company during a job interview (github.com)', 'Artificial leaf produces first drugs using sunlight (newatlas.com)', '50 U.S. states and territories announce broad antitrust investigation of Google (washingtonpost.com)', 'Health system sues thousands of patients, seizes pay and puts liens on homes (msn.com)', 'GCC eBPF for Linux port has landed (gnu.org)', 'Using Spotify data to predict what songs will be hits (techxplore.com)', 'Monochromatic Fundus Photography (opsweb.org)', 'A Hologram Suggests How Space Could Pop into Existence (nautil.us)']\n"
     ]
    }
   ],
   "source": [
    "links_table = response.html.find(\".itemlist\", first = True)\n",
    "#print(links_table.html)\n",
    "\n",
    "article_name_and_link_list = links_table.find(\".athing\")\n",
    "\n",
    "article_headlines = []\n",
    "\n",
    "for article_html in article_name_and_link_list:\n",
    "    article_headlines.append(article_html.text.split(\"\\n\")[1])\n",
    "\n",
    "\n",
    "print(article_headlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rank': 1, 'headline': '9th Circuit holds that scraping a public website does not violate the CFAA [pdf] (uscourts.gov)', 'url': 'http://cdn.ca9.uscourts.gov/datastore/opinions/2019/09/09/17-16783.pdf'}\n",
      "{'rank': 2, 'headline': '94k Bitcoin (1B USD) transferred from unknown wallet to unknown wallet (twitter.com)', 'url': 'https://twitter.com/whale_alert/status/1169815776733220866'}\n",
      "{'rank': 3, 'headline': 'Daytripper (github.com)', 'url': 'https://github.com/dekuNukem/daytripper'}\n",
      "{'rank': 4, 'headline': 'Running GitHub on Rails 6.0 (github.blog)', 'url': 'https://github.blog/2019-09-09-running-github-on-rails-6-0/'}\n",
      "{'rank': 5, 'headline': '‘We May Have to Shoot Down This Aircraft’ (politico.com)', 'url': 'https://www.politico.com/magazine/story/2019/09/05/911-oral-history-flight-93-book-excerpt-228001'}\n",
      "{'rank': 6, 'headline': 'Unencrypted patient medical information is being broadcast across Vancouver (openprivacy.ca)', 'url': 'https://openprivacy.ca/blog/2019/09/09/open-privacy-discovers-vancouver-patient-medical-data-breach/'}\n",
      "{'rank': 7, 'headline': \"Menstruation Apps Are Sharing Users' Data (privacyinternational.org)\", 'url': 'https://www.privacyinternational.org/long-read/3196/no-bodys-business-mine-how-menstruation-apps-are-sharing-your-data'}\n",
      "{'rank': 8, 'headline': 'New games for the Atari Lynx (atarigamer.com)', 'url': 'https://atarigamer.com/articles/in-2019-we-have-eleven-new-games-for-the-atari-lynx'}\n",
      "{'rank': 9, 'headline': 'The Buffalo Public Library in 1983 (1883) (wikisource.org)', 'url': 'https://en.wikisource.org/wiki/The_Buffalo_Public_Library_in_1983'}\n",
      "{'rank': 10, 'headline': 'Maturity (gitlab.com)', 'url': 'https://about.gitlab.com/direction/maturity/'}\n",
      "{'rank': 11, 'headline': 'Why Positive Cashflow Matters (avc.com)', 'url': 'https://avc.com/2019/09/why-positive-cashflow-matters/'}\n",
      "{'rank': 12, 'headline': 'Project Naptha: Make Text in Browser Images Selectable (projectnaptha.com)', 'url': 'https://projectnaptha.com/'}\n",
      "{'rank': 13, 'headline': 'Ribbon (YC S17) is hiring data engineers. Help us simplify healthcare (ribbonhealth.com)', 'url': 'https://www.ribbonhealth.com/careers/'}\n",
      "{'rank': 14, 'headline': 'Waltz: A Distributed Write-Ahead Log (wepay.com)', 'url': 'https://wecode.wepay.com/posts/waltz-a-distributed-write-ahead-log'}\n",
      "{'rank': 15, 'headline': 'Hong Kong Protests: The most striking illustrations from the movement so far (digitalartsonline.co.uk)', 'url': 'https://www.digitalartsonline.co.uk/features/illustration/hong-kong-protests-most-striking-illustrations-from-movement-so-far/'}\n",
      "{'rank': 16, 'headline': 'GPT-2 is not as dangerous as OpenAI thought it might be (nostalgebraist.tumblr.com)', 'url': 'https://nostalgebraist.tumblr.com/post/187579086034/it-seems-pretty-clear-to-me-by-now-that-gpt-2-is'}\n",
      "{'rank': 17, 'headline': 'Announcing Ballerina 1.0 a langauge with structural type system (ballerina.io)', 'url': 'https://v1-0.ballerina.io/'}\n",
      "{'rank': 18, 'headline': 'Show HN: Enter your URL and view CVEs affecting your stack over last 6 months (secalerts.co)', 'url': 'https://secalerts.co/security-audit'}\n",
      "{'rank': 19, 'headline': 'High doses of vitamin D do not strengthen bone (jamanetwork.com)', 'url': 'https://jamanetwork.com/journals/jama/article-abstract/2748796'}\n",
      "{'rank': 20, 'headline': 'Scientists Discover New Evidence of the Asteroid That Killed Off the Dinosaurs (wsj.com)', 'url': 'https://www.wsj.com/articles/scientists-discover-new-evidence-of-the-asteroid-that-killed-off-the-dinosaurs-11568055601?mod=rsswn'}\n",
      "{'rank': 21, 'headline': 'Sunsetting Python 2 (python.org)', 'url': 'https://www.python.org/doc/sunset-python-2/'}\n",
      "{'rank': 22, 'headline': 'The Book Disease: On Bibliomania (laphamsquarterly.org)', 'url': 'https://www.laphamsquarterly.org/roundtable/book-disease'}\n",
      "{'rank': 23, 'headline': 'Questions to ask a company during a job interview (github.com)', 'url': 'https://github.com/viraptor/reverse-interview'}\n",
      "{'rank': 24, 'headline': 'Artificial leaf produces first drugs using sunlight (newatlas.com)', 'url': 'https://newatlas.com/science/artificial-leaf-first-drugs-sunlight/'}\n",
      "{'rank': 25, 'headline': '50 U.S. states and territories announce broad antitrust investigation of Google (washingtonpost.com)', 'url': 'https://www.washingtonpost.com/technology/2019/09/09/states-us-territories-announce-broad-antitrust-investigation-google/'}\n",
      "{'rank': 26, 'headline': 'Health system sues thousands of patients, seizes pay and puts liens on homes (msn.com)', 'url': 'https://www.msn.com/en-us/news/us/uva-has-ruined-us-health-system-sues-thousands-of-patients-seizing-paychecks-and-putting-liens-on-homes/ar-AAH27ni'}\n",
      "{'rank': 27, 'headline': 'GCC eBPF for Linux port has landed (gnu.org)', 'url': 'https://gcc.gnu.org/ml/gcc-patches/2019-08/msg01987.html'}\n",
      "{'rank': 28, 'headline': 'Using Spotify data to predict what songs will be hits (techxplore.com)', 'url': 'https://techxplore.com/news/2019-09-spotify-songs.html'}\n",
      "{'rank': 29, 'headline': 'Monochromatic Fundus Photography (opsweb.org)', 'url': 'https://www.opsweb.org/page/monochromatic'}\n",
      "{'rank': 30, 'headline': 'A Hologram Suggests How Space Could Pop into Existence (nautil.us)', 'url': 'http://nautil.us/issue/75/story/a-hologram-shows-how-space-could-pop-into-existence'}\n"
     ]
    }
   ],
   "source": [
    "single_article = article_name_and_link_list[0]\n",
    "\n",
    "def article_html_to_dict(single_article):\n",
    "    \n",
    "    article_rank_raw = single_article.find(\".rank\", first = True).text\n",
    "    article_rank = int(article_rank_raw.replace(\".\",\"\"))\n",
    "    article_url = single_article.find(\".storylink\", first=True).attrs[\"href\"]\n",
    "    article_headline = single_article.text.split(\"\\n\")[1]\n",
    "\n",
    "    article_data = {\n",
    "        \"rank\": article_rank, \n",
    "        \"headline\": article_headline, \n",
    "        \"url\": article_url}\n",
    "    return article_data\n",
    "\n",
    "\n",
    "#For single article\n",
    "# single_article = article_name_and_link_list[0]\n",
    "# print(article_html_to_dict(single_article)) \n",
    "\n",
    "#For all the the articles\n",
    "for single_article in article_name_and_link_list:\n",
    "    print(article_html_to_dict(single_article))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'td' class=('subtext',)>\n"
     ]
    }
   ],
   "source": [
    "single_article_subtext = response.html.find(\".subtext\")[0]\n",
    "print(single_article_subtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'href'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-97abfe4fac9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpoints_subtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_article_subtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mby_subtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".hnuser\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mhow_long_ago_subtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".age\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'href'"
     ]
    }
   ],
   "source": [
    "single_article_subtext = response.html.find(\".subtext\")[0]\n",
    "points_subtext = single_article_subtext.find(\".score\", first=True).text\n",
    "\n",
    "by_subtext = \".hnuser\".href\n",
    "\n",
    "how_long_ago_subtext = (\".age\")\n",
    "total_comments_subtext = (\".age\").href \n",
    "print(single_article_subtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 points by donohoe 10 hours ago | hide | 181 comments\n"
     ]
    }
   ],
   "source": [
    "single_article_subtext = response.html.find(\".subtext\")[0]\n",
    "\n",
    "article_rank_raw_subtext = single_article_subtext.find(\".subtext\", first = True).text\n",
    "\n",
    "print(article_rank_raw_subtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 points by donohoe 10 hours ago | hide | 181 comments\n"
     ]
    }
   ],
   "source": [
    "single_article_subtext = response.html.find(\".subtext\")[0]\n",
    "\n",
    "article_rank_raw_subtext = single_article_subtext.find(\".subtext\", first = True).text\n",
    "\n",
    "print(article_rank_raw_subtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'td' class=('subtext',)>\n",
      "768 points\n",
      "user?id=donohoe\n",
      "10 hours ago\n"
     ]
    }
   ],
   "source": [
    "#single_article_subtext = response.html.find(\".subtext\")[0]\n",
    "\n",
    "single_article_subtext = response.html.find(\".subtext\")[0]\n",
    "\n",
    "points_subtext = single_article_subtext.find(\".score\", first=True).text\n",
    "by_subtext = single_article_subtext.find(\".hnuser\", first=True).attrs[\"href\"]\n",
    "how_long_ago_subtext = single_article_subtext.find(\".age\", first=True).text\n",
    "#total_comments_subtext = single_article_subtext.find(\".age\", first=True).attrs[\"href\"]\n",
    "\n",
    "print(single_article_subtext)\n",
    "print(points_subtext)\n",
    "print(by_subtext)\n",
    "print(how_long_ago_subtext)\n",
    "#print(total_comments_subtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_article_subtext = response.html.find(\".subtext\")[0]\n",
    "\n",
    "# def sub_info_article(single_article_subtext):\n",
    "    \n",
    "#     points_subtext = single_article_subtext.find(\".score\", first=True).text\n",
    "#     by_subtext = single_article_subtext.find(\".hnuser\", first=True).attrs[\"href\"]\n",
    "#     how_long_ago_subtext = single_article_subtext.find(\".age\", first=True).text\n",
    "     \n",
    "#     user_comments_data = {\"points\":points_subtext, \n",
    "#                           \"by\":by_subtext, \n",
    "#                           \"ago\":how_long_ago_subtext\n",
    "#                          }\n",
    "#     return user_comments_data\n",
    "\n",
    "# sub_info_article(single_article_subtext)\n",
    "\n",
    "#-------\n",
    "# for single_article_subtext in response.html.find(\".subtext\"):\n",
    "#     print(single_article_subtext)\n",
    "\n",
    "# for single_article_subtext in article_name_and_link_list:\n",
    "#     print(single_article_subtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Element' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3873357f11e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msingle_article_subtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0msubinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_article_subinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0msub_info_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-3873357f11e2>\u001b[0m in \u001b[0;36mget_article_subinfo\u001b[0;34m(single_article_subtext)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpoints_subtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_article_subtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_subtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mby_subtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_article_subtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".hnuser\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Element' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "def get_article_subinfo(single_article_subtext):\n",
    "    \n",
    "    points_subtext = single_article_subtext.find(\".score\", first=True).text\n",
    "    score = int(points_subtext.split(\" \")[0])\n",
    "    \n",
    "    by_subtext = single_article_subtext.find(\".hnuser\", first=True).text\n",
    "    how_long_ago_subtext = single_article_subtext.find(\".age\", first=True).text\n",
    "    \n",
    "    comment_subtext = single_article_subtext.find(\"a\")[-1].text\n",
    "    no_of_comments_str = comment_subtext.split()[0]\n",
    "    \n",
    "    if no_of_comments_str == \"discuss\":\n",
    "        no_of_comments = 0\n",
    "    else:\n",
    "        no_of_comments = int(no_of_comments_str)\n",
    "    \n",
    "    \n",
    "    user_comments_data = {\"by\":by_subtext, \n",
    "                          \"points\":score, \n",
    "                          \"ago\":how_long_ago_subtext,\n",
    "                          \"comments\":no_of_comments}\n",
    "    return user_comments_data\n",
    "\n",
    "single_article_subtext = response.html.find(\".subtext\")\n",
    "\n",
    "sub_info_list = []\n",
    "\n",
    "for subtext in single_article_subtext:\n",
    "    subinfo = get_article_subinfo(subtext)\n",
    "    sub_info_list.append(subinfo)\n",
    "\n",
    "print(sub_info_list)\n",
    "\n",
    "\n",
    "\n",
    "#sub_text_list = response.html.find(\".subtext\")\n",
    "\n",
    "# sub_info_list = []\n",
    "\n",
    "# for subtext in sub_text_list:\n",
    "#     subinfo = get_article_subinfo(subtext)\n",
    "#     sub_info_list.append(subinfo)\n",
    "\n",
    "# print(sub_info_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_text_list = response.html.find(\".subtext\")\n",
    "\n",
    "# sub_info_list = list(map(get_article_subinfo, sub_text_list))\n",
    "\n",
    "# print(sub_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c09b7fd7ffc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_text_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0msubinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_article_subinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0msub_info_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-c09b7fd7ffc4>\u001b[0m in \u001b[0;36mget_article_subinfo\u001b[0;34m(single_article_subtext)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_article_subinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_article_subtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpoints_subtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_article_subtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_subtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "def get_article_maininfo(single_article_maintext):\n",
    "    article_rank_raw = single_article_maintext.find(\".rank\", first=True).text\n",
    "    article_rank = int(article_rank_raw.split(\" \")[0])\n",
    "    username = sing\n",
    "\n",
    "def get_article_subinfo(single_article_subtext):\n",
    "    \n",
    "    points_subtext = single_article_subtext.find(\".score\", first=True).text\n",
    "    score = int(points_subtext.split(\" \")[0])\n",
    "    \n",
    "    by_subtext = single_article_subtext.find(\".hnuser\", first=True).text\n",
    "    how_long_ago_subtext = single_article_subtext.find(\".age\", first=True).text\n",
    "    comment_subtext = single_article_subtext.find(\"a\")[-1].text\n",
    "    no_of_comments_str = comment_subtext.split()[0]\n",
    "    \n",
    "    if no_of_comments_str == \"discuss\":\n",
    "        no_of_comments = 0\n",
    "    else:\n",
    "        no_of_comments = int(no_of_comments_str)\n",
    "    \n",
    "    \n",
    "    user_comments_data = {\"by\":by_subtext, \n",
    "                          \"points\":score, \n",
    "                          \"ago\":how_long_ago_subtext,\n",
    "                          \"comments\":no_of_comments}\n",
    "    return user_comments_data\n",
    "\n",
    "\n",
    "sub_text_list = response.html.find(\".subtext\")\n",
    "\n",
    "sub_info_list = []\n",
    "\n",
    "for subtext in sub_text_list:\n",
    "    subinfo = get_article_subinfo(subtext)\n",
    "    sub_info_list.append(subinfo)\n",
    "\n",
    "print(sub_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
